Напишите утилиту, которая на основе заданных текстов генерирует свои.

— Один скрипт должен считать входной корпус из файла (ов), обработать его и в каком-то формате записать «модель» в другой файл

— Другой скрипт должен принимать на вход путь до этой модели и опционально префикс генерируемого текста и генерировать его правдоподобное продолжение (несколько следующих слов)

Можете решать любыми методами. Приведенный ниже подход — это совет, а не строгое техзадание.

Как автор предлагает

Автор когда-то сам такое писал и предлагает следующий простой и эффективный метод: биграммнная языковая модель.

По большому тексту для каждого слова составляется список слов, которые могут идти после него. В ML это называется обучением. Хранить эту информацию можно в виде словаря: {слово : [одно-следующее-слово, другое-следующее-слово, ...]}.

При самой генерации следует выбрать какое-нибудь начальное слово. В ML оно называется состоянием. Все следующие слова последовательно случайно выбираются из списка слов, идущих после текущего в словаре. Выбор из этого словаря можно делать через random.choice. В ML это называется сэмплированием.

Основной код должен быть разбит на две части: обучение и генерация.

Обучение:

    Считать входные данные из файлов.
    Очистить тексты: выкидывать неалфавитные символы, приводить к lowercase.
    Разбить тексты на слова (в ML это называется токенизацией).
    Сохранить модель в каком-нибудь формате, который позволяет восстановить слова и частоты биграмм.


Генерация:

    Загрузить модель.
    Инициализировать её каким-нибудь сидом.
    Сгенерировать последовательность нужной длины.


Детали:

    Удобно создать для обучения и генерации отдельные файлы и реализовать консольный интерфейс к ним через argparse.
    Для работы с текстами может пригодиться библиотека регулярных выражений re.
    Соблюдайте, пожалуйста, pep8. Пишите хороший код.
    Следуйте принципам ООП. Оберните модель в класс, у которого будет методы fit и generate.
    Для сохранения модели удобно использовать pickle или dill.
    Обучать модель можно на чем угодно – от «Войны и мира» и «Гарри Поттера» до текстов Билли Айлиш и протоколов съездов КПСС.
